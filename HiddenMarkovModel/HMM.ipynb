{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4eb95b0",
   "metadata": {},
   "source": [
    "# Getting milliyetNER train data and parsing sentences for building hidden markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f538e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "words = []\n",
    "entity = []\n",
    "sentences = []\n",
    "tokens = []\n",
    "entitys = []\n",
    "with open(\"./train.txt\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line=='\\n':\n",
    "            sentences.append(list(zip(words, entity)))\n",
    "            words=[]\n",
    "            entity=[]\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "        tokens.append(line_split[0])\n",
    "        entitys.append(line_split[1])\n",
    "        words.append(line_split[0])\n",
    "        entity.append(line_split[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eff415",
   "metadata": {},
   "source": [
    "# Creating probability matrix train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d0b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens                 \"         $         %         &         '         (  \\\n",
      "entitys                                                                      \n",
      "B-LOCATION      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-ORGANIZATION  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-PERSON        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-LOCATION      0.000000  0.000000  0.000000  0.000000  0.003115  0.000000   \n",
      "I-ORGANIZATION  0.000000  0.000000  0.000000  0.002730  0.004949  0.000000   \n",
      "I-PERSON        0.000634  0.000000  0.000000  0.000000  0.001267  0.000000   \n",
      "O               0.023062  0.000003  0.000027  0.000024  0.046473  0.003584   \n",
      "\n",
      "tokens                )         +         ,         -  ...   şüpheyi  \\\n",
      "entitys                                                ...             \n",
      "B-LOCATION      0.00000  0.000000  0.000000  0.000000  ...  0.000000   \n",
      "B-ORGANIZATION  0.00000  0.000000  0.000000  0.000000  ...  0.000000   \n",
      "B-PERSON        0.00000  0.000000  0.000075  0.000000  ...  0.000000   \n",
      "I-LOCATION      0.00000  0.000000  0.002336  0.010903  ...  0.000000   \n",
      "I-ORGANIZATION  0.00000  0.000000  0.001536  0.020307  ...  0.000000   \n",
      "I-PERSON        0.00000  0.000000  0.000000  0.003801  ...  0.000000   \n",
      "O               0.00344  0.000027  0.061742  0.006764  ...  0.000003   \n",
      "\n",
      "tokens          şüpnhelenilen     şüyuu       şıh       şık    şıklık  \\\n",
      "entitys                                                                 \n",
      "B-LOCATION           0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-ORGANIZATION       0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B-PERSON             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-LOCATION           0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-ORGANIZATION       0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "I-PERSON             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "O                    0.000003  0.000003  0.000003  0.000021  0.000003   \n",
      "\n",
      "tokens           şımarık    şırnak  şırnaklı         ’  \n",
      "entitys                                                 \n",
      "B-LOCATION      0.000000  0.002267  0.000000  0.000000  \n",
      "B-ORGANIZATION  0.000000  0.000000  0.000000  0.000000  \n",
      "B-PERSON        0.000000  0.000000  0.000000  0.000000  \n",
      "I-LOCATION      0.000000  0.000000  0.000000  0.000000  \n",
      "I-ORGANIZATION  0.000000  0.000000  0.000000  0.000000  \n",
      "I-PERSON        0.000000  0.000000  0.000000  0.000000  \n",
      "O               0.000003  0.000000  0.000003  0.000005  \n",
      "\n",
      "[7 rows x 56237 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokens = [token.lower() for token in tokens]\n",
    "# print(tokens[0])\n",
    "# print(entitys)\n",
    "\n",
    "df = pd.DataFrame(tokens,entitys).reset_index().rename(columns={0:'tokens','index':'entitys'})\n",
    "df['values']=1\n",
    "df = df.pivot_table(index='entitys', columns='tokens', aggfunc='sum').fillna(0)\n",
    "df = df.div(df.sum(axis=1), axis=0)\n",
    "df.columns = df.columns.droplevel(0)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2636a0",
   "metadata": {},
   "source": [
    "# Creating transition probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75eb9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B-LOCATION  B-ORGANIZATION  B-PERSON  I-LOCATION  \\\n",
      "<s>               0.714286        0.714286  0.714286    0.000000   \n",
      "B-LOCATION        0.006657        0.001985  0.000467    0.105103   \n",
      "B-ORGANIZATION    0.008235        0.002786  0.000484    0.000000   \n",
      "B-PERSON          0.002650        0.001363  0.005982    0.000000   \n",
      "I-LOCATION        0.007843        0.000784  0.003137    0.301176   \n",
      "I-ORGANIZATION    0.004281        0.002568  0.000856    0.000000   \n",
      "I-PERSON          0.003838        0.003338  0.001502    0.000000   \n",
      "O                 0.019638        0.017229  0.029171    0.000000   \n",
      "\n",
      "                I-ORGANIZATION  I-PERSON         O  \n",
      "<s>                   0.000000  0.000000  0.285714  \n",
      "B-LOCATION            0.000000  0.000000  0.885788  \n",
      "B-ORGANIZATION        0.386702  0.000000  0.601792  \n",
      "B-PERSON              0.000000  0.434878  0.555126  \n",
      "I-LOCATION            0.000000  0.000000  0.687059  \n",
      "I-ORGANIZATION        0.456678  0.000000  0.535616  \n",
      "I-PERSON              0.000000  0.095294  0.896028  \n",
      "O                     0.000000  0.000000  0.933962  \n"
     ]
    }
   ],
   "source": [
    "df2 = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    for index in range(len(sentence)-1):\n",
    "        first_token = sentence[index][1]\n",
    "        next_token = sentence[index+1][1]\n",
    "        df2.append({'first_token':first_token,'next_token':next_token})\n",
    "\n",
    "        \n",
    "        \n",
    "df2 = pd.DataFrame(df2)\n",
    "df2['values'] = 1\n",
    "df2 = df2.pivot_table(index='first_token',columns='next_token',aggfunc='sum').fillna(0)\n",
    "df2 = df2.div(df2.sum(axis=1), axis=0)\n",
    "df2.columns = df2.columns.droplevel(0)\n",
    "\n",
    "df2 = pd.concat([pd.DataFrame(columns=['B-LOCATION','B-ORGANIZATION','B-PERSON','I-LOCATION','I-ORGANIZATION','I-PERSON','O']\n",
    "                              ,index=['<s>'],data=[[5/7,5/7,5/7,0,0,0,2/7]]),df2],axis=0)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5b576",
   "metadata": {},
   "source": [
    "# getting test data for test our model and get prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9bba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_tokens = []\n",
    "test_entites = []\n",
    "with open(\"./test.txt\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line=='\\n':\n",
    "#             sentences.append(list(zip(words, entity)))\n",
    "#             words = []\n",
    "#             entity = []\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "        test_tokens.append(line_split[0])\n",
    "        test_entites.append(line_split[1])\n",
    "\n",
    "list_of_entity = []\n",
    "previous = '<s>'\n",
    "\n",
    "tokens = [token.lower() for token in test_tokens]\n",
    "\n",
    "for token in tokens:\n",
    "    try:\n",
    "        df[token]\n",
    "    except:\n",
    "        list_of_entity.append((token, 'O'))\n",
    "        continue\n",
    "    matrix = df[token].multiply(df2.loc[previous])\n",
    "    previous = df.index[np.argmax(matrix)]\n",
    "    token_label_pair = (token,previous)\n",
    "    list_of_entity.append(token_label_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f85c68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_entities=[]\n",
    "for i in list_of_entity:\n",
    "    predicted_entities.append(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92692813",
   "metadata": {},
   "source": [
    "# Comparing true POS tags with predicted ones without 'O' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196d1588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON       0.89      0.75      0.82      1603\n",
      "      I-PERSON       0.91      0.52      0.67       803\n",
      "    B-LOCATION       0.79      0.86      0.83      1126\n",
      "B-ORGANIZATION       0.85      0.55      0.67       873\n",
      "I-ORGANIZATION       0.63      0.15      0.24       864\n",
      "    I-LOCATION       0.76      0.34      0.47       211\n",
      "\n",
      "     micro avg       0.84      0.60      0.70      5480\n",
      "     macro avg       0.81      0.53      0.61      5480\n",
      "  weighted avg       0.82      0.60      0.67      5480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "labels = ['B-PERSON',\n",
    " 'I-PERSON',\n",
    " 'B-LOCATION',\n",
    " 'B-ORGANIZATION',\n",
    " 'I-ORGANIZATION',\n",
    " 'I-LOCATION']\n",
    "\n",
    "metrics_table_test = metrics.classification_report(test_entites, predicted_entities, labels=labels)\n",
    "print(metrics_table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d0ffe",
   "metadata": {},
   "source": [
    "# Getting dev.txt data to predict values and getting compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a90e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON       0.90      0.86      0.88      1400\n",
      "      I-PERSON       0.90      0.68      0.78       680\n",
      "    B-LOCATION       0.81      0.92      0.86       942\n",
      "B-ORGANIZATION       0.87      0.66      0.75       842\n",
      "I-ORGANIZATION       0.68      0.26      0.37       589\n",
      "    I-LOCATION       0.68      0.54      0.60       107\n",
      "\n",
      "     micro avg       0.85      0.72      0.78      4560\n",
      "     macro avg       0.81      0.65      0.71      4560\n",
      "  weighted avg       0.84      0.72      0.76      4560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_tokens = []\n",
    "test_entites = []\n",
    "with open(\"./dev.txt\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line=='\\n':\n",
    "#             sentences.append(list(zip(words, entity)))\n",
    "#             words = []\n",
    "#             entity = []\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "        test_tokens.append(line_split[0])\n",
    "        test_entites.append(line_split[1])\n",
    "\n",
    "list_of_entity = []\n",
    "previous = '<s>'\n",
    "\n",
    "tokens = [token.lower() for token in test_tokens]\n",
    "\n",
    "for token in tokens:\n",
    "    try:\n",
    "        df[token]\n",
    "    except:\n",
    "        list_of_entity.append((token, 'O'))\n",
    "        continue\n",
    "    matrix = df[token].multiply(df2.loc[previous])\n",
    "    previous = df.index[np.argmax(matrix)]\n",
    "    token_label_pair = (token,previous)\n",
    "    list_of_entity.append(token_label_pair)\n",
    "    \n",
    "predicted_entities=[]\n",
    "for i in list_of_entity:\n",
    "    predicted_entities.append(i[1])\n",
    "\n",
    "metrics_table_dev = metrics.classification_report(test_entites, predicted_entities, labels=labels)\n",
    "print(metrics_table_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b390d7b",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I did get slightly better results in dev.txt data. I found some typing error in test.txt and dev.txt data and I added try block code for that reason. It catches typos. Maybe dev.txt data has less typo than test.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21957a1a",
   "metadata": {},
   "source": [
    "# Writing metric table results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de3b2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metric_table_test.txt', 'w') as f:\n",
    "    f.write(metrics_table_test)\n",
    "with open('metric_table_dev.txt', 'w') as f:\n",
    "    f.write(metrics_table_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
