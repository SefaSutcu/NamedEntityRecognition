{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1307663e",
   "metadata": {},
   "source": [
    "# Getting milliyetNER train data and parsing sentences for building CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833e537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "entity = []\n",
    "train_sentences = []\n",
    "# tokens = []\n",
    "# entitys = []\n",
    "with open(\"./train.txt\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line=='\\n':\n",
    "            train_sentences.append(list(zip(words, entity)))\n",
    "            words=[]\n",
    "            entity=[]\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "#         tokens.append(line_split[0])\n",
    "#         entitys.append(line_split[1])\n",
    "        words.append(line_split[0])\n",
    "        entity.append(line_split[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312d6661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ATİLLA', 'B-PERSON'),\n",
       " ('Mutman', 'I-PERSON'),\n",
       " (',', 'O'),\n",
       " ('İzmir', 'B-LOCATION'),\n",
       " ('milletvekili', 'O')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0878171",
   "metadata": {},
   "source": [
    "# Defining features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bba0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "#         'postag': postag,\n",
    "#         'postag[:2]': postag[:2],        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "#             '-1:postag': postag1,\n",
    "#             '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "#             '+1:postag': postag1,\n",
    "#             '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e6e9b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'ati̇lla',\n",
       " 'word[-3:]': 'LLA',\n",
       " 'word[-2:]': 'LA',\n",
       " 'word.isupper()': True,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': 'mutman',\n",
       " '+1:word.istitle()': True,\n",
       " '+1:word.isupper()': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sentences[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf183a",
   "metadata": {},
   "source": [
    "# getting test data for test our model and get prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96addc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "words = []\n",
    "entity = []\n",
    "with open(\"./test.txt\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line=='\\n':\n",
    "            test_sentences.append(list(zip(words, entity)))\n",
    "            words = []\n",
    "            entity = []\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "        words.append(line_split[0])\n",
    "        entity.append(line_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577e9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_sentences]\n",
    "y_train = [sent2labels(s) for s in train_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59281082",
   "metadata": {},
   "source": [
    "# Building CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06002cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac20b4",
   "metadata": {},
   "source": [
    "# There is much more O entities in data set, but we're more interested in other entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaec4c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PERSON',\n",
       " 'I-PERSON',\n",
       " 'B-LOCATION',\n",
       " 'B-ORGANIZATION',\n",
       " 'I-ORGANIZATION',\n",
       " 'I-LOCATION']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f895d8",
   "metadata": {},
   "source": [
    "# Extracting features for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d79e388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [sent2features(s) for s in test_sentences]\n",
    "y_test = [sent2labels(s) for s in test_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3cda09",
   "metadata": {},
   "source": [
    "# Getting prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3560611",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34744816",
   "metadata": {},
   "source": [
    "# Printing comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c1e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON      0.926     0.871     0.898      1603\n",
      "      I-PERSON      0.929     0.928     0.928       803\n",
      "    B-LOCATION      0.946     0.893     0.919      1126\n",
      "B-ORGANIZATION      0.908     0.855     0.880       873\n",
      "I-ORGANIZATION      0.906     0.838     0.871       864\n",
      "    I-LOCATION      0.891     0.697     0.782       211\n",
      "\n",
      "     micro avg      0.924     0.870     0.896      5480\n",
      "     macro avg      0.918     0.847     0.880      5480\n",
      "  weighted avg      0.923     0.870     0.895      5480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_table_test_crf = metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3)\n",
    "print(metric_table_test_crf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80002f",
   "metadata": {},
   "source": [
    "# Getting dev data and extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb9dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = []\n",
    "words = []\n",
    "entity = []\n",
    "with open(\"./dev.txt\", encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line=='\\n':\n",
    "            dev_sentences.append(list(zip(words, entity)))\n",
    "            words = []\n",
    "            entity = []\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "        words.append(line_split[0])\n",
    "        entity.append(line_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012dbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [sent2features(s) for s in dev_sentences]\n",
    "y_test = [sent2labels(s) for s in dev_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032dd285",
   "metadata": {},
   "source": [
    "# Getting prediction values for dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f147273",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40db824",
   "metadata": {},
   "source": [
    "# Printing comparing results for dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04fb2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON      0.947     0.926     0.937      1400\n",
      "      I-PERSON      0.918     0.943     0.930       680\n",
      "    B-LOCATION      0.970     0.930     0.950       942\n",
      "B-ORGANIZATION      0.943     0.924     0.933       842\n",
      "I-ORGANIZATION      0.876     0.932     0.903       589\n",
      "    I-LOCATION      0.930     0.869     0.899       107\n",
      "\n",
      "     micro avg      0.936     0.929     0.932      4560\n",
      "     macro avg      0.931     0.921     0.925      4560\n",
      "  weighted avg      0.937     0.929     0.933      4560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_table_dev_crf = metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3)\n",
    "print(metric_table_dev_crf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455d4c6",
   "metadata": {},
   "source": [
    "# Comparing metric tables from previous assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "965f7145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t    \u001b[4m\u001b[1m\u001b[94mTEST DATA CRF MODEL\u001b[0m\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON      0.926     0.871     0.898      1603\n",
      "      I-PERSON      0.929     0.928     0.928       803\n",
      "    B-LOCATION      0.946     0.893     0.919      1126\n",
      "B-ORGANIZATION      0.908     0.855     0.880       873\n",
      "I-ORGANIZATION      0.906     0.838     0.871       864\n",
      "    I-LOCATION      0.891     0.697     0.782       211\n",
      "\n",
      "     micro avg      0.924     0.870     0.896      5480\n",
      "     macro avg      0.918     0.847     0.880      5480\n",
      "  weighted avg      0.923     0.870     0.895      5480\n",
      "\n",
      "\t\t\t\t\u001b[4m\u001b[1m\u001b[94mTEST DATA HMM\u001b[0m\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON       0.89      0.75      0.82      1603\n",
      "      I-PERSON       0.91      0.52      0.67       803\n",
      "    B-LOCATION       0.79      0.86      0.83      1126\n",
      "B-ORGANIZATION       0.85      0.55      0.67       873\n",
      "I-ORGANIZATION       0.63      0.15      0.24       864\n",
      "    I-LOCATION       0.76      0.34      0.47       211\n",
      "\n",
      "     micro avg       0.84      0.60      0.70      5480\n",
      "     macro avg       0.81      0.53      0.61      5480\n",
      "  weighted avg       0.82      0.60      0.67      5480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "   BLUE = '\\033[94m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print('\\t\\t\\t    ' + color.UNDERLINE + color.BOLD + color.BLUE + 'TEST DATA CRF MODEL' + color.END + '\\n')\n",
    "\n",
    "print(metric_table_test_crf)\n",
    "print('\\t\\t\\t\\t' + color.UNDERLINE + color.BOLD + color.BLUE + 'TEST DATA HMM' + color.END + '\\n')\n",
    "with open('metric_table_test.txt') as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caf20223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t    \u001b[4m\u001b[1m\u001b[94mDEV DATA CRF MODEL\u001b[0m\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON      0.947     0.926     0.937      1400\n",
      "      I-PERSON      0.918     0.943     0.930       680\n",
      "    B-LOCATION      0.970     0.930     0.950       942\n",
      "B-ORGANIZATION      0.943     0.924     0.933       842\n",
      "I-ORGANIZATION      0.876     0.932     0.903       589\n",
      "    I-LOCATION      0.930     0.869     0.899       107\n",
      "\n",
      "     micro avg      0.936     0.929     0.932      4560\n",
      "     macro avg      0.931     0.921     0.925      4560\n",
      "  weighted avg      0.937     0.929     0.933      4560\n",
      "\n",
      "\t\t\t\t\u001b[4m\u001b[1m\u001b[94mDEV DATA HMM\u001b[0m\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      B-PERSON       0.90      0.86      0.88      1400\n",
      "      I-PERSON       0.90      0.68      0.78       680\n",
      "    B-LOCATION       0.81      0.92      0.86       942\n",
      "B-ORGANIZATION       0.87      0.66      0.75       842\n",
      "I-ORGANIZATION       0.68      0.26      0.37       589\n",
      "    I-LOCATION       0.68      0.54      0.60       107\n",
      "\n",
      "     micro avg       0.85      0.72      0.78      4560\n",
      "     macro avg       0.81      0.65      0.71      4560\n",
      "  weighted avg       0.84      0.72      0.76      4560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\t    ' + color.UNDERLINE + color.BOLD + color.BLUE + 'DEV DATA CRF MODEL' + color.END + '\\n')\n",
    "print(metric_table_dev_crf)\n",
    "print('\\t\\t\\t\\t' + color.UNDERLINE + color.BOLD + color.BLUE + 'DEV DATA HMM' + color.END + '\\n')\n",
    "with open('metric_table_dev.txt') as f:\n",
    "    contents = f.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6e123",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "As we can see from tables, CRF model is better HMM. For CRF model again we get better results from dev data than test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
